{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pilotNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hbg1345/GrandTheftAutopilot/blob/master/pilotNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL6vLyIElvwD"
      },
      "source": [
        "# PilotNet training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk_e_HzMc2df"
      },
      "source": [
        "## Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hJwANvl35F"
      },
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import sklearn\r\n",
        "import glob\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bDDeCtemVuk"
      },
      "source": [
        "## Mount Google Drive into Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bVXH_5rmEVs",
        "outputId": "120a7b37-8349-4343-f5af-7f3fdce3ad18"
      },
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB2G5mbCfFsC"
      },
      "source": [
        "## [In Progress] Copy datasets from Google Drive to Colab\n",
        "\n",
        "Since the overhead caused by network transaction is NOT negligible, one have to\n",
        "copy all the data required at the beginning of the experiment for best performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8smPtbKvfEa8",
        "outputId": "28cbfe71-5775-4703-fb3b-bf0d84f670c8"
      },
      "source": [
        "import sys\n",
        "# set base path to the top of our project directory\n",
        "base = Path('/content/drive/MyDrive/AutopilotDrive')\n",
        "sys.path.append(str(base))\n",
        "\n",
        "dataset_path = base/'dataset.zip'\n",
        "\n",
        "# copy zipped dataset from Google Drive\n",
        "!cp \"{dataset_path}\"\n",
        "\n",
        "# unzip the files\n",
        "!unzip -q dataset.zip\n",
        "\n",
        "# remove zipped file to save storage\n",
        "!rm dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: missing destination file operand after '/content/drive/MyDrive/AutopilotDrive/dataset.zip'\n",
            "Try 'cp --help' for more information.\n",
            "unzip:  cannot find or open dataset.zip, dataset.zip.zip or dataset.zip.ZIP.\n",
            "rm: cannot remove 'dataset.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4Pnosn9hxVS"
      },
      "source": [
        "## Load Dataset from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7OAB5aRAumV"
      },
      "source": [
        "import pathlib\r\n",
        "\r\n",
        "# set directory to datasets\r\n",
        "data_dir = \"/content/drive/MyDrive/AutopilotDrive/dataset/\"\r\n",
        "data_dir = pathlib.Path(data_dir)\r\n",
        "\r\n",
        "# check # of images\r\n",
        "# img_count = len(list(data_dir.glob('*/imgs/*.jpg')))\r\n",
        "# print(img_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBEVjkEjlnuZ"
      },
      "source": [
        "## Define Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APw29y97AZgF"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "# Keras implemented with TF backend\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, BatchNormalization\r\n",
        "from tensorflow.keras.optimizers import SGD\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\r\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o9VurATz3zC"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juim2r12TWaW"
      },
      "source": [
        "# define custom scikit-learn estimator & transformer performing MinMaxScaling on each channels\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "class ImageMinMaxScaler(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self):\n",
        "    return\n",
        "\n",
        "  def fit(self, X=None, y=None):\n",
        "    return self\n",
        "    \n",
        "  def transform(self, X, y=None):\n",
        "    # scale every pixel value to fit in [0, 1]\n",
        "    result = X / 255\n",
        "\n",
        "    return result\n",
        "\n",
        "  def fit_transform(self, X, y=None):\n",
        "    self.fit()\n",
        "\n",
        "    result = self.transform(X)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0QIKZAvnM13"
      },
      "source": [
        "\n",
        "# define custom scikit-learn estimator & transformer resizing given image\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class ImageResizer(TransformerMixin):\n",
        "\n",
        "  def __init__(self, target_size=(200, 66)):\n",
        "      self.target_size = target_size\n",
        "      return\n",
        "\n",
        "  def fit(self, X=None, y=None):\n",
        "      return self\n",
        "\n",
        "  def transform(self, X):\n",
        "      result = cv2.resize(X, self.target_size, interpolation=cv2.INTER_AREA)\n",
        "      return np.swapaxes(result, axis1=0, axis2=1)\n",
        "\n",
        "  def fit_transform(self, X, y=None):\n",
        "      return self.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61D4s1vsRAm9"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipe = Pipeline([                     \n",
        "                     ('ImageMinMaxScaler', ImageMinMaxScaler()), # scales the pixel values to range [0, 1]\n",
        "                     ('ImageResizer', ImageResizer())  # resizes given image to match the input layer size of the NN\n",
        "\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALqJ3oLis-3R"
      },
      "source": [
        "## Define Custom dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQcQaVsDtB1I"
      },
      "source": [
        "import pathlib\n",
        "import math\n",
        "\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class Dataloader(Sequence):\n",
        "  def __init__(self, dataset_dir, batch_size=32, shuffle=False):\n",
        "    self.dataset_dir = pathlib.Path(dataset_dir)\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle= shuffle\n",
        "    self.num_img = len(list(self.dataset_dir.glob('imgs/*.jpg')))\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return math.ceil(self.num_img / self.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POkakZB-DoQF"
      },
      "source": [
        "def img_to_arr(p):\r\n",
        "    with image.load_img(p) as img:\r\n",
        "        img = image.img_to_array(img)\r\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzB_Xsq3d6Ji"
      },
      "source": [
        "target_dataset = \"/content/drive/MyDrive/AutopilotDrive/dataset/\"\n",
        "df = pd.read_csv(target_dataset + \"/datasets_mod.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqgNmcpgeMHi"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array # Image Related\n",
        "\n",
        "random_indices = np.random.randint(low=0, high=len(df), size=10)\n",
        "\n",
        "X_train = np.array([img_to_arr(target_dataset + \"../\" + image_name) for image_name in df['drive_view'].iloc[random_indices]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9InTaOj5ZrH",
        "outputId": "9fa4d2d5-76c9-4ad3-b4d2-9b6009d0ff14"
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 455, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVfQrl7FIQJs"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "for i in range(len(random_indices)):\r\n",
        "    scaler_R = StandardScaler().fit(X_train[i][:,:,0])\r\n",
        "    scaler_G = StandardScaler().fit(X_train[i][:,:,1])\r\n",
        "    scaler_B = StandardScaler().fit(X_train[i][:,:,2])\r\n",
        "\r\n",
        "def normalize(img, scaler_R, scaler_G, scaler_B):\r\n",
        "    img[:,:,0] = scaler_R.transform(img[:,:,0])\r\n",
        "    img[:,:,1] = scaler_G.transform(img[:,:,1])\r\n",
        "    img[:,:,2] = scaler_B.transform(img[:,:,2])\r\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_h4pmPf_qd_"
      },
      "source": [
        "# define generator that loops through the data\r\n",
        "def generator(df, batch_size, img_shape, should_shuffle):\r\n",
        "    # shuffle dataframe for each epoch\r\n",
        "    if should_shuffle:\r\n",
        "        df = shuffle(df)\r\n",
        "        \r\n",
        "    img_list = df['drive_view']\r\n",
        "    steer = df['control']\r\n",
        "    \r\n",
        "    # create empty batch\r\n",
        "    batch_img = np.zeros((batch_size,) + img_shape)\r\n",
        "    batch_label = np.zeros((batch_size, 1))\r\n",
        "    \r\n",
        "    index = 0\r\n",
        "    while True:\r\n",
        "        for i in range(batch_size):\r\n",
        "            img_name = img_list.iloc[index]\r\n",
        "            arr = img_to_arr(target_dataset + \"../\" + img_name)\r\n",
        "            \r\n",
        "            batch_img[i] = normalize(arr, scaler_R, scaler_G, scaler_B)\r\n",
        "            batch_label[i] = steer.iloc[index]\r\n",
        "            \r\n",
        "            index += 1\r\n",
        "            if index == len(img_list):\r\n",
        "                index = 0\r\n",
        "            \r\n",
        "        yield batch_img, batch_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGN7iNorsw3p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "674cf2d6-9d8d-4338-b232-40962869aebe"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>drive_view</th>\n",
              "      <th>control</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  control\n",
              "0           0  ...        3\n",
              "1           1  ...        3\n",
              "2           2  ...        1\n",
              "3           3  ...        1\n",
              "4           4  ...        1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCGzKddWxlIG",
        "outputId": "09503e0f-889a-4b02-e76d-689c655f00ce"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70991, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab6f1B2yAtD9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "df_train, df_valid = train_test_split(df, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgaDuBDgEQy3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "b0cecf69-c0e7-481d-fc2c-21b9b7c8b3bd"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>drive_view</th>\n",
              "      <th>control</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5099</th>\n",
              "      <td>5282</td>\n",
              "      <td>5282</td>\n",
              "      <td>5283</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9441</th>\n",
              "      <td>11295</td>\n",
              "      <td>515</td>\n",
              "      <td>11296</td>\n",
              "      <td>./dataset/210119_12-16-36_data/imgs/drive_view...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15205</th>\n",
              "      <td>17059</td>\n",
              "      <td>6279</td>\n",
              "      <td>17060</td>\n",
              "      <td>./dataset/210119_12-16-36_data/imgs/drive_view...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32888</th>\n",
              "      <td>34742</td>\n",
              "      <td>6619</td>\n",
              "      <td>34743</td>\n",
              "      <td>./dataset/210119_12-24-51_data/imgs/drive_view...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5888</th>\n",
              "      <td>6071</td>\n",
              "      <td>6071</td>\n",
              "      <td>6072</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...  control\n",
              "5099         5282  ...        1\n",
              "9441        11295  ...        3\n",
              "15205       17059  ...        1\n",
              "32888       34742  ...        0\n",
              "5888         6071  ...        3\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb3rXnWHEWvs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac5ade24-f0d9-4af6-a520-0ee69795bdf1"
      },
      "source": [
        "df_train['drive_view'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./dataset/210119_12-14-48_data/imgs/drive_view5282.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Zqjk3aAak1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2ba0c2-d3a6-4260-fc47-3b84a1d3720f"
      },
      "source": [
        "sample_image = img_to_arr(target_dataset + \"../\" + df_train['drive_view'].iloc[0])\r\n",
        "input_shape = sample_image.shape\r\n",
        "batch_size = 32\r\n",
        "train_steps = (df_train.shape[0] / batch_size) + 1\r\n",
        "val_steps = (df_valid.shape[0] / batch_size) + 1\r\n",
        "\r\n",
        "print(\"input_shape: %s, batch_size: %d, train_steps: %d, val_steps: %d\" % \r\n",
        "      (input_shape, batch_size, train_steps, val_steps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (256, 455, 3), batch_size: 32, train_steps: 1775, val_steps: 444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3tjsRo-BadG"
      },
      "source": [
        "train_batch = generator(df_train, batch_size, input_shape, True)\r\n",
        "val_batch = generator(df_valid, batch_size, input_shape, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkhDzeinlicQ"
      },
      "source": [
        "# Define Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16xeasSVL1mK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c914ba1-6533-4303-d600-e8e03f1233bb"
      },
      "source": [
        "drop_out_rate = 0.2\n",
        "\n",
        "model = models.Sequential()\n",
        "# model.add(Rescaling(scale=1./255))\n",
        "\n",
        "# three Conv2D layers with 5 x 5 kernels, and 2 x 2 strides\n",
        "model.add(Conv2D(filters=24, kernel_size=(5, 5), strides=(2, 2),\n",
        "                              padding='valid', activation='relu', input_shape=(256, 455, 3)))\n",
        "model.add(Conv2D(filters=36, kernel_size=(5, 5), strides=(2, 2),\n",
        "                              padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=48, kernel_size=(5, 5), strides=(2, 2),\n",
        "                              padding='valid', activation='relu'))\n",
        "\n",
        "# two Conv2D layers with 3 x 3 kernels, and no strides\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "                              padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "                              padding='valid', activation='relu'))\n",
        "\n",
        "# and data flows to three fully-connected layers\n",
        "model.add(Flatten())   # (None, 1152)\n",
        "model.add(Dense(units=1152))\n",
        "model.add(Dropout(rate=drop_out_rate))\n",
        "model.add(Dense(units=100))\n",
        "model.add(Dropout(rate=drop_out_rate))\n",
        "model.add(Dense(units=50))\n",
        "model.add(Dropout(rate=drop_out_rate))\n",
        "model.add(Dense(units=10))\n",
        "model.add(Dropout(rate=drop_out_rate))\n",
        "model.add(Dense(units=5, activation='softmax'))\n",
        "\n",
        "# build the pilotNet model\n",
        "model.build(input_shape=(None, 200, 66, 3))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 126, 226, 24)      1824      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 61, 111, 36)       21636     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 29, 54, 48)        43248     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 27, 52, 64)        27712     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 25, 50, 64)        36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 80000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1152)              92161152  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               115300    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 55        \n",
            "=================================================================\n",
            "Total params: 92,413,415\n",
            "Trainable params: 92,413,415\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Po1fP6_L6a2"
      },
      "source": [
        "model.compile(optimizer='adam',\r\n",
        "                loss='categorical_crossentropy',\r\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5TLazMtC8Bl"
      },
      "source": [
        "model_path = target_dataset + \"/model\"\r\n",
        "# define callbacks\r\n",
        "cur_model = 'PilotNet_v1'\r\n",
        "csv_logger = CSVLogger(os.path.join(\"./\", cur_model + '.log'))\r\n",
        "\r\n",
        "model_file_name= os.path.join(model_path, cur_model + '-{epoch:03d}-{val_loss:.5f}.h5')\r\n",
        "checkpoint = ModelCheckpoint(model_file_name, verbose=0, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_BfVlnFDEWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af88e329-5fa0-4127-a017-174a36145196"
      },
      "source": [
        "print(type(train_batch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'generator'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiEsMSXhDJJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "5ce85719-21f0-42ce-875a-da92af90cf45"
      },
      "source": [
        "model.fit_generator(train_batch, train_steps, epochs=20, verbose=1, callbacks=[csv_logger, checkpoint], validation_data=val_batch, validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "  45/1775 [..............................] - ETA: 4:13:04 - loss: 31710222516.7481 - accuracy: 5.8834e-04"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e64d81176b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ti4AFXGtFZx"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJuQqek8tGgr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUNp44PC90_S"
      },
      "source": [
        "# Act based on Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5eBMJ_R-DuC"
      },
      "source": [
        "vk_code = [0x57, 0x41, 0x53, 0x44]\r\n",
        "out = model.predict(input)\r\n",
        "out = encoder.inverse_transform(out)[0]\r\n",
        "if out != 4:\r\n",
        "  press(out, 0.01)\r\n",
        "\r\n",
        "def press(key, seconds):\r\n",
        "    import win32con, win32api\r\n",
        "    import time\r\n",
        "    win32api.keybd_event(vk_code[key], 0, 0, 0) # key down\r\n",
        "    time.sleep(seconds)\r\n",
        "    win32api.keybd_event(vk_code[key], 0, win32con.KEYEVENTF_KEYUP, 0) # key up"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}